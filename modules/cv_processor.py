# modules/cv_processor.py

import os  # x·ª≠ l√Ω t∆∞∆°ng t√°c v·ªõi h·ªá th·ªëng file v√† bi·∫øn m√¥i tr∆∞·ªùng
import re  # x·ª≠ l√Ω bi·ªÉu th·ª©c ch√≠nh quy
import json  # parse v√† dump JSON
import time  # x·ª≠ l√Ω th·ªùi gian v√† sleep retry
import logging  # ghi log
from typing import List, Dict, Optional  # khai b√°o ki·ªÉu
from pathlib import Path

import pandas as pd  # x·ª≠ l√Ω DataFrame
pd.set_option("display.max_colwidth", None)  # hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß n·ªôi dung c√°c c·ªôt
import docx  # ƒë·ªçc file .docx

# --- Thi·∫øt l·∫≠p logger cho module ---
logger = logging.getLogger(__name__)  # l·∫•y logger theo t√™n module
logger.setLevel(logging.INFO)  # m·ª©c ƒë·ªô log t·ªëi thi·ªÉu INFO
fmt = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")  # ƒë·ªãnh d·∫°ng log
# handler xu·∫•t log ra console
stream_h = logging.StreamHandler()  
stream_h.setFormatter(fmt)
logger.addHandler(stream_h)
# handler xu·∫•t log ra file trong th∆∞ m·ª•c log
Path("log").mkdir(parents=True, exist_ok=True)
file_h = logging.FileHandler("log/cv_processor.log", encoding="utf-8")
file_h.setFormatter(fmt)
logger.addHandler(file_h)

# --- C·∫•u h√¨nh extractor PDF: pdfminer, PyPDF2 ho·∫∑c PyMuPDF ---
_PDF_EX: Optional[str]
try:
    from pdfminer.high_level import extract_text
    _PDF_EX = "pdfminer"  # ∆∞u ti√™n pdfminer n·∫øu c√†i ƒë·∫∑t
except ImportError:
    try:
        import PyPDF2
        _PDF_EX = "pypdf2"  # fallback sang PyPDF2
    except ImportError:
        try:
            import fitz  # PyMuPDF
            _PDF_EX = "pymupdf"  # fallback sang PyMuPDF
        except ImportError:
            _PDF_EX = None  # kh√¥ng c√≥ th∆∞ vi·ªán PDF n√†o

from .llm_client import LLMClient  # client LLM m·∫∑c ƒë·ªãnh
from .config import ATTACHMENT_DIR, OUTPUT_CSV  # c·∫•u h√¨nh th∆∞ m·ª•c v√† file xu·∫•t
from .prompts import CV_EXTRACTION_PROMPT  # prompt LLM ƒë·ªÉ tr√≠ch xu·∫•t CV

class CVProcessor:
    """
    L·ªõp x·ª≠ l√Ω file CV: ƒë·ªçc text, g·ªçi LLM ho·∫∑c regex fallback, tr·∫£ v·ªÅ DataFrame
    """
    def __init__(self, fetcher: Optional[object] = None, llm_client: Optional[LLMClient] = None):
        """Kh·ªüi t·∫°o: c·∫•p fetcher (ƒë·ªçc email) v√† LLM client"""
        self.fetcher = fetcher  # ƒë·ªëi t∆∞·ª£ng c√≥ method fetch_cv_attachments()
        self.llm_client = llm_client or LLMClient()  # client LLM m·∫∑c ƒë·ªãnh

    def _extract_pdf(self, path: str) -> str:
        """
        ƒê·ªçc text t·ª´ file PDF b·∫±ng th∆∞ vi·ªán t∆∞∆°ng ·ª©ng
        Tr·∫£ v·ªÅ chu·ªói r·ªóng n·∫øu kh√¥ng c√≥ library
        """
        if _PDF_EX == "pdfminer":
            return extract_text(path)
        elif _PDF_EX == "pypdf2":
            from PyPDF2 import PdfReader
            txt = ""
            for p in PdfReader(path).pages:
                txt += p.extract_text() or ""
            return txt
        elif _PDF_EX == "pymupdf":
            import fitz
            doc = fitz.open(path)
            txt = "".join(page.get_text() for page in doc)
            doc.close()
            return txt
        logger.error("‚ùå Kh√¥ng c√≥ th∆∞ vi·ªán PDF ph√π h·ª£p ƒë·ªÉ tr√≠ch xu·∫•t text.")
        return ""

    def extract_text(self, path: str) -> str:
        """
        ƒê·ªçc vƒÉn b·∫£n t·ª´ file PDF ho·∫∑c DOCX
        Tr·∫£ v·ªÅ chu·ªói text, log c·∫£nh b√°o n·∫øu ƒë·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£
        """
        ext = os.path.splitext(path)[1].lower()  # l·∫•y ph·∫ßn m·ªü r·ªông
        try:
            if ext == ".pdf":
                return self._extract_pdf(path)
            if ext == ".docx":
                doc = docx.Document(path)
                return "\n".join(p.text for p in doc.paragraphs)
            logger.warning(f"‚ö†Ô∏è ƒê·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£: {path}")
        except Exception as e:
            logger.error(f"L·ªói khi ƒë·ªçc file {path}: {e}")
        return ""

    def extract_info_with_llm(self, text: str) -> Dict:
        """
        G·ªçi LLM ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin theo prompt, retry t·ªëi ƒëa 3 l·∫ßn
        Parse JSON t·ª´ k·∫øt qu·∫£ ho·∫∑c fallback regex
        """
        if not text.strip():  # n·∫øu chu·ªói r·ªóng, tr·∫£ v·ªÅ dict r·ªóng
            return {}

        for attempt in range(1, 4):  # retry 3 l·∫ßn
            try:
                # gh√©p prompt v√† text, g·ª≠i cho LLM
                resp = self.llm_client.generate_content([CV_EXTRACTION_PROMPT, text])
                # t√¨m JSON trong code block ho·∫∑c thu·∫ßn JSON
                m = re.search(r'```json\s*([\s\S]+?)\s*```|({[\s\S]+})', resp)
                if m:
                    data = m.group(1) or m.group(2)
                    return json.loads(data)
                logger.warning(f"AI tr·∫£ v·ªÅ kh√¥ng ph·∫£i JSON, resp: {resp}")
                break
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå L·ªói parse JSON t·ª´ AI: {e}")
                break
            except Exception as e:
                msg = str(e).lower()
                # n·∫øu l·ªói quota, retry sau wait
                if any(code in msg for code in ("quota", "429", "resource_exhausted")) and attempt < 3:
                    wait = 2 ** attempt
                    logger.warning(f"Quota exceeded, retry sau {wait}s")
                    time.sleep(wait)
                    continue  # th·ª≠ l·∫°i
                logger.error(f"‚ùå L·ªói khi g·ªçi GenAI: {e}")
                break

        logger.info("üîÑ D√πng fallback regex ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin")
        return self._fallback_regex(text)

    def _fallback_regex(self, text: str) -> Dict:
        """
        D√πng regex ƒë∆°n gi·∫£n ƒë·ªÉ tr√≠ch xu·∫•t c√°c tr∆∞·ªùng: t√™n, email, ƒëi·ªán tho·∫°i, h·ªçc v·∫•n, kinh nghi·ªám, ƒë·ªãa ch·ªâ, k·ªπ nƒÉng
        Tr·∫£ v·ªÅ dict v·ªõi c√°c key t∆∞∆°ng ·ª©ng
        """
        patterns = {
            "ten": r"(?:(?:H·ªç t√™n|T√™n)[:\-\s]+)([^\n]+)",
            "email": r"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+)",
            "dien_thoai": r"(\+?\d[\d\-\s]{7,}\d)",
            "hoc_van": r"(?:(?:H·ªçc v·∫•n|Education)[:\-\s]+)([^\n]+)",
            "kinh_nghiem": r"(?:(?:Kinh nghi·ªám|Experience)[:\-\s]+)([^\n]+)",
            "dia_chi": r"(?:(?:ƒê·ªãa ch·ªâ|Address)[:\-\s]+)([^\n]+)",
            "ky_nang": r"(?:(?:K·ªπ nƒÉng|Skills?)[:\-\s]+)([^\n]+)",
        }
        info: Dict[str, str] = {}
        for k, p in patterns.items():
            m = re.search(p, text, re.IGNORECASE)
            info[k] = m.group(1).strip() if m else ""
        return info

    def process(self) -> pd.DataFrame:
        """
        T√¨m t·∫•t c·∫£ file CV (fetcher ho·∫∑c th∆∞ m·ª•c attachments), tr√≠ch xu·∫•t info, tr·∫£ v·ªÅ DataFrame
        """
        # fetch t·ª´ email n·∫øu c√≥ fetcher
        files: List[str] = self.fetcher.fetch_cv_attachments() if self.fetcher else []
        if not files:
            logger.info("üîç Kh√¥ng t√¨m th·∫•y qua fetcher, d√≤ th∆∞ m·ª•c attachments...")
            files = [
                os.path.join(ATTACHMENT_DIR, f)
                for f in os.listdir(ATTACHMENT_DIR)
                if f.lower().endswith((".pdf", ".docx"))
            ]
        if not files:
            logger.info("‚ÑπÔ∏è Kh√¥ng c√≥ file CV n√†o trong th∆∞ m·ª•c.")
            return pd.DataFrame()  # tr·∫£ v·ªÅ DataFrame r·ªóng n·∫øu kh√¥ng c√≥ file

        rows: List[Dict[str, str]] = []
        for path in files:
            txt = self.extract_text(path)  # ƒë·ªçc text file
            info = self.extract_info_with_llm(txt) or {}
            # gom th√¥ng tin v√†o dict
            rows.append({
                "Ngu·ªìn": os.path.basename(path),
                "H·ªç t√™n": info.get("ten", ""),
                "Email": info.get("email", ""),
                "ƒêi·ªán tho·∫°i": info.get("dien_thoai", ""),
                "ƒê·ªãa ch·ªâ": info.get("dia_chi", ""),
                "H·ªçc v·∫•n": info.get("hoc_van", ""),
                "Kinh nghi·ªám": info.get("kinh_nghiem", ""),
                "K·ªπ nƒÉng": info.get("ky_nang", ""),
            })

        df = pd.DataFrame(rows, columns=[
            "Ngu·ªìn",
            "H·ªç t√™n",
            "Email",
            "ƒêi·ªán tho·∫°i",
            "ƒê·ªãa ch·ªâ",
            "H·ªçc v·∫•n",
            "Kinh nghi·ªám",
            "K·ªπ nƒÉng",
        ])  # t·∫°o DataFrame t·ª´ list dict v·ªõi th·ª© t·ª± c·ªôt c·ªë ƒë·ªãnh
        return df  # tr·∫£ v·ªÅ k·∫øt qu·∫£

    def save_to_csv(self, df: pd.DataFrame, output: str = OUTPUT_CSV):
        """
        Ghi ƒë√® file CSV m·ªói l·∫ßn ch·∫°y; n·∫øu mu·ªën append, c√≥ th·ªÉ chuy·ªÉn mode v√† header
        """
        df.to_csv(output, index=False, encoding="utf-8-sig")  # l∆∞u file
        logger.info(f"‚úÖ ƒê√£ l∆∞u {len(df)} h·ªì s∆° v√†o {output}")
